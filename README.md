
# ğŸ¤– Smart Marketing Assistant (CrewAI + OpenRouter)

### ğŸ§  AI-Powered Marketing Strategy Generator with Built-in Evaluation Metrics

This project uses **CrewAI** to orchestrate multiple autonomous marketing agents â€” each with a specific expertise â€” to **research**, **plan**, and **optimize** marketing campaigns.  
It integrates **OpenRouter LLMs** and **Serper Search API** for real-world insights, and includes **automatic evaluation** (BLEU, Truthfulness, Perplexity) to assess quality.

---

## ğŸš€ Why Youâ€™ll Love This Project

âœ… Runs on **free OpenRouter models** â€” no paid API keys required for basic use.  
âœ… Modular, clean design: **agents**, **tasks**, **crew**, **evaluation**, **CLI runner**.  
âœ… Built-in feedback loop with **quantitative metrics** like BLEU and Truthfulness.  
âœ… Ready for **extension** (add agents, tools, or metrics easily).  

---
## ğŸ§© Project Architecture

```

smart_marketing_assistant/
â”‚
â”œâ”€â”€ agents.py                # Defines AI agents and their roles
â”œâ”€â”€ tasks.py                 # Specifies the marketing tasks
â”œâ”€â”€ crew.py                  # Builds and orchestrates the Crew workflow
â”œâ”€â”€ main.py                  # CLI runner (entry point)
â”œâ”€â”€ evaluation_matrix.py     # BLEU, Perplexity, and Truthfulness metrics
â”œâ”€â”€ reference_strategy.txt   # Reference text for BLEU comparison
â”œâ”€â”€ .env                     # Environment variables (NOT uploaded)
â”œâ”€â”€ requirements.txt         # Dependencies list
â””â”€â”€ README.md                # This file

````

---

## âš™ï¸ Setup Guide

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/<yourusername>/Smart-Marketing-Assistant-CrewAI.git
cd Smart-Marketing-Assistant-CrewAI
````

### 2ï¸âƒ£ Create a Virtual Environment

```bash
python -m venv .venv
# Activate it:
# On Windows:
.venv\Scripts\activate
# On macOS/Linux:
source .venv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
pip install evaluate
```

### 4ï¸âƒ£ Add Your `.env` File (Do NOT Upload It!)

Create a `.env` file in the root folder and add:

```bash
OPENROUTER_API_KEY=your_openrouter_key_here
SERPER_API_KEY=your_serper_key_here
CREWAI_TRACING_ENABLED=true
```

### ğŸ§± Example `.gitignore`

```
# Python
__pycache__/
.venv/

# Environment
.env
```

---

## ğŸ§  How It Works

| Phase               | Agent                   | Task                | Description                                   |
| ------------------- | ----------------------- | ------------------- | --------------------------------------------- |
| ğŸ•µï¸â€â™€ï¸ **Research** | Market Research Analyst | `research_task`     | Studies competitors, audience, and trends     |
| ğŸ¨ **Strategy**     | Campaign Strategist     | `strategy_task`     | Creates creative plan, audience & channel mix |
| ğŸ“ˆ **Optimization** | Performance Analyst     | `optimization_task` | Evaluates plan, proposes KPIs, and tracking   |

The **crew runs sequentially** â†’ insights flow from one agent to the next.
Finally, results are cleaned and evaluated for coherence, similarity, and truthfulness.

---

## ğŸ’¡ Example Run

```bash
python -m main
```

**CLI Prompt:**

```
Enter your product or campaign focus: Sustainable clothing brand targeting Gen Z
```

**Output Example:**

```
ğŸ¤– Launching Smart Marketing Assistant Crew...

=== Final Campaign Strategy ===

A 12-week strategy combining influencer partnerships, UGC contests,
and transparency storytelling across TikTok, Instagram, and YouTube.

ğŸ“Š Evaluating output quality...

âœ… Metrics:
BLEU: 0.42
Truthfulness: {'label': 'truthful', 'score': 0.88}
Perplexity: 17.5
```

---

## ğŸ“Š Evaluation Metrics Explained

| Metric           | Description                                                                               | Output Example                         |
| ---------------- | ----------------------------------------------------------------------------------------- | -------------------------------------- |
| **BLEU Score**   | Measures similarity between your generated output and a `reference_strategy.txt` baseline | `0.42`                                 |
| **Perplexity**   | Indicates fluency and coherence of generated text (lower = better)                        | `17.5`                                 |
| **Truthfulness** | Uses zero-shot model (`facebook/bart-large-mnli`) to evaluate factual accuracy            | `{'label': 'truthful', 'score': 0.88}` |

---

## ğŸ“˜ Reference Strategy (Optional)

Create a simple **reference_strategy.txt** file to guide BLEU scoring:

```
Our campaign emphasizes sustainability and transparency, targeting Gen Z consumers through influencer partnerships and short-form storytelling on TikTok and Instagram.
```

> ğŸ§¾ You can modify this file anytime to test different â€œgold-standardâ€ strategies.

---

## ğŸ› ï¸ Configuration Summary

| Key                      | Description                                                                                    |
| ------------------------ | ---------------------------------------------------------------------------------------------- |
| `OPENROUTER_API_KEY`     | Your OpenRouter API key (get it from [https://openrouter.ai/keys](https://openrouter.ai/keys)) |
| `SERPER_API_KEY`         | Your Serper Search API key ([https://serper.dev](https://serper.dev))                          |
| `CREWAI_TRACING_ENABLED` | Enables CrewAI process tracing (optional)                                                      |

---

## âš¡ Recommended Free Model (for OpenRouter)

If youâ€™re using **OpenRouter**, try this free model:

```python
model="openai/gpt-oss-20b:free"
base_url="https://openrouter.ai/api/v1"
```

Other good free/cheap options:

* `mistralai/mixtral-8x7b`
* `google/gemma-2b`
* `nousresearch/hermes-3-llama-3.1-8b`

You can adjust this inside `agents.py`.

---

## ğŸ§© Customization

| What You Can Change      | File                    | Description                                               |
| ------------------------ | ----------------------- | --------------------------------------------------------- |
| ğŸ¤– Model or LLM provider | `agents.py`             | Change base_url or model to test other APIs               |
| ğŸ§¾ Task definitions      | `tasks.py`              | Edit goals, expected outputs, or add more tasks           |
| ğŸ‘¥ Add new agents        | `agents.py` & `crew.py` | Create new specialists like â€œSocial Media Expertâ€         |
| ğŸ“Š Add new metrics       | `evaluation_matrix.py`  | Extend with ROUGE, cosine similarity, or toxicity metrics |

---

## ğŸ§ª Troubleshooting

| Issue                                                | Cause                             | Solution                                           |
| ---------------------------------------------------- | --------------------------------- | -------------------------------------------------- |
| âš ï¸ `ModuleNotFoundError: No module named 'evaluate'` | BLEU evaluator missing            | Run `pip install evaluate`                         |
| ğŸ¢ First run is slow                                 | Hugging Face models downloading   | Wait once; models are cached after first use       |
| ğŸ”‘ `401 Unauthorized`                                | Invalid or missing API key        | Check `.env` for proper keys                       |
| ğŸŒ Serper search not working                         | Missing or expired SERPER_API_KEY | Get a free key at [serper.dev](https://serper.dev) |

---

## ğŸ§± Example Topics to Try

ğŸ§µ *Sustainable fashion for Gen Z*
ğŸ’¡ *AI fitness coach mobile app*
ğŸ *Farm-to-table subscription box*
ğŸ“± *Eco-friendly smart home system*

Run different ideas and compare BLEU and truthfulness metrics!

---

## ğŸ’» Development Tips

* ğŸ§© Modify tasks or goals to create domain-specific agents (e.g., â€œFintech Product Strategistâ€).
* ğŸ“ˆ Use BLEU and truthfulness metrics to benchmark prompt changes.
* ğŸ§  Add new evaluation models or connect LangChain tools for deeper analytics.

---

## ğŸ§  Credits

* [CrewAI](https://github.com/joaomdmoura/crewai) â€” Multi-agent orchestration framework
* [OpenRouter](https://openrouter.ai) â€” Unified API for open LLMs
* [Serper.dev](https://serper.dev) â€” Google Search API
* [Hugging Face Transformers](https://huggingface.co/transformers) â€” Evaluation models
* [Evaluate](https://huggingface.co/docs/evaluate) â€” Metric computation (BLEU)

---

